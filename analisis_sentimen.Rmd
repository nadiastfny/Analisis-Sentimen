---
title: "Analisis-Review-Clothes"
author: "Nadia & Alvin"
date: "6/4/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
## Akses library yang dibutuhkan
## here() starts at D:/Kuliah/Semester 6/Prak DS/Projek/Projek-Praktikum
```{r  }
library(tm)
library(wordcloud2)
library(vroom)
library(here)
```
 
```{r}
#  load dataset
setwd("D:/Kuliah/Semester 6/Prak DS/Projek/Projek-Praktikum")
dataReview <- readLines('data-review.csv')

textid <- Corpus(VectorSource(dataReview))

removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
reviewclean <- tm_map(textid, removeURL)

removeNL <- function(y) gsub("\n", " ", y)
reviewclean <- tm_map(reviewclean, removeNL)

replacecomma <- function(y) gsub(",", "", y)
reviewclean <- tm_map(reviewclean, replacecomma)

removeRT <- function(y) gsub("RT ", "", y)
reviewclean <- tm_map(reviewclean, removeRT)

removetitik2 <- function(y) gsub(":", "", y)
reviewclean <- tm_map(reviewclean, removetitik2)

removetitikkoma <- function(y) gsub(";", " ", y)
reviewclean <- tm_map(reviewclean, removetitikkoma)

removetitik3 <- function(y) gsub("p…", "", y)
reviewclean <- tm_map(reviewclean, removetitik3)

removeamp <- function(y) gsub("&amp;", "", y)
reviewclean <- tm_map(reviewclean, removeamp)

removeUN <- function(z) gsub("@\\w+", "", z)
reviewclean <- tm_map(reviewclean, removeUN)

remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)

reviewclean <- tm_map(reviewclean,remove.all)
reviewclean <- tm_map(reviewclean, removePunctuation)
reviewclean <- tm_map(reviewclean, tolower)
myStopwords = readLines("stopword_en.txt")
reviewclean <- tm_map(reviewclean,removeWords,myStopwords)

dataframe<-data.frame(text=unlist(sapply(reviewclean, `[`)), stringsAsFactors=F)
View(dataframe)
write.csv(dataframe,file = 'reviewClean.csv')
```

## Metodenya

```{r required}
 if (!require("pacman")) install.packages("pacman")
pacman::p_load(wordcloud, tm, tidyr, tidytext, syuzhet, ngram, NLP, RColorBrewer, RTextTools, e1071, caret, knitr)
```
 
```{r}
library(e1071)
library(caret)
library(syuzhet)
```
 
```{r bagi data}
#digunakan untuk membaca file csv yang sudah di cleaning data 
review_dataset<-read.csv("reviewClean.csv",stringsAsFactors = FALSE)

#digunakan untuk mengeset variabel cloumn text menjadi char
review <-as.character(review_dataset$text)

#Calls the NRC sentiment dictionary to calculate the presence of eight different emotions and their corresponding valence in a text file.
get_nrc_sentiment('happy')
get_nrc_sentiment('excitement')

s<-get_nrc_sentiment(review)

review_combine<-cbind(review_dataset$text,s)

hasil_analisis<-data.frame(review_combine, stringsAsFactors=FALSE)
View(hasil_analisis)
write.csv(hasil_analisis,file = 'hasil_sentimen.csv')

par(mar=rep(3,4))
a<- barplot(colSums(s),col=rainbow(10),ylab='count',main='sentiment analisis')
iki_ba <- a
```

```{r bagi data2}
#library untuk penggunaan corpus dalam cleaning data
library(tm)
library(RTextTools)

#library yang terdapat sebuah algoritma naivebayes
library(e1071)
library(dplyr)
library(caret)
df<-read.csv("reviewClean.csv",stringsAsFactors = FALSE)
glimpse(df)

#Set the seed of R‘s random number generator, which is useful for creating simulations or random objects that can be reproduced.
set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)

corpus<-Corpus(VectorSource(df$text))

#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)

 
df.train<-df[1:2410,]
df.test<-df[2411:4822,]

dtm.train<-dtm[1:2410,]
dtm.test<-dtm[2411:4822,]

corpus.clean.train<-corpus.clean[1:2410]
corpus.clean.test<-corpus.clean[2411:4822]

dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

#dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)


library(wordcloud)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))

```

## Membuat Shiny nya
```{r global}
library(shiny)
library(here)
library(vroom)
library(dplyr)
library(ggplot2)
library(plotly)
library(syuzhet)

review2<- read.csv("reviewClean.csv", header = TRUE)
reviewid <- review2$text

analisis <- read.csv("hasil_sentimen.csv", header = TRUE)  #membuka data hasil sentimen

review_dataset<-read.csv("reviewClean.csv",stringsAsFactors = FALSE)

ui <- fluidPage(
    titlePanel("SENTIMENT ANALYSIS WOMEN'S E-COMMERCE CLOTHING REVIEWS"),
        mainPanel(
            tabsetPanel(type = "tabs",
                         tabPanel("Data Review", DT::dataTableOutput('tbl')), # Output Data Dalam Tabel
                        tabPanel("Data Analisis Sentimen", DT::dataTableOutput('sentiment')),
                        tabPanel("Plot", plotOutput("plot")), 
                       
                        tabPanel("Wordcloud", plotOutput("Wordcloud"))
                        )
        )
    )
# SERVER
server <- function(input, output) {
    
    # Output Data
    output$tbl = DT::renderDataTable({
        DT::datatable(review2, options = list(lengthChange = FALSE))
    })
    
     # Output Data Sentiment
    output$sentiment = DT::renderDataTable({
        DT::datatable(analisis, options = list(lengthChange = FALSE))
    })
    
    # Output Plot
    output$plot <- renderPlot({review_dataset<-read.csv("reviewClean.csv",stringsAsFactors = FALSE)

review<-as.character(review_dataset$text)

get_nrc_sentiment('happy')
get_nrc_sentiment('excitement')
s<-get_nrc_sentiment(review)

review_combine<-cbind(review_dataset$text,s)
par(mar=rep(3,4))
barplot(colSums(s),col=rainbow(10),ylab='count',main='sentiment analisis')
    }, height=400)
    
    # Output Wordcloud
    output$Wordcloud <- renderPlot({
    set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)


#df$index=as.factor(df$index)
corpus<-Corpus(VectorSource(df$text))

#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)
 
df.train<-df[1:2410,]
df.test<-df[2411:4822,]

dtm.train<-dtm[1:2410,]
dtm.test<-dtm[2411:4822,]

corpus.clean.train<-corpus.clean[1:2410]
corpus.clean.test<-corpus.clean[2411:4822]

dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

#dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)

classifier<-naiveBayes(trainNB,df.train$text,laplace = 1)
library(wordcloud)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
  })
}
shinyApp(ui = ui, server = server)
```